{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RealTimeVoiceCloning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "801675df44c54402812089ec9d41fc98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ButtonView",
            "style": "IPY_MODEL_65bad0699f154671bf734f6f8234a085",
            "_dom_classes": [],
            "description": "Record Your Voice",
            "_model_name": "ButtonModel",
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "tooltip": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_828540d503694590ac6bb5e24135afd1",
            "_model_module": "@jupyter-widgets/controls",
            "icon": ""
          }
        },
        "65bad0699f154671bf734f6f8234a085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "828540d503694590ac6bb5e24135afd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhDehA7sT-Gx"
      },
      "source": [
        "# Real-Time Voice Cloning\n",
        "\n",
        "This is a colab demo notebook using the open source project [CorentinJ/Real-Time-Voice-Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning)\n",
        "to clone a voice.\n",
        "\n",
        "For other deep-learning Colab notebooks, visit [tugstugi/dl-colab-notebooks](https://github.com/tugstugi/dl-colab-notebooks).\n",
        "\n",
        "\n",
        "Original issue: https://github.com/tugstugi/dl-colab-notebooks/issues/18\n",
        "\n",
        "## Setup CorentinJ/Real-Time-Voice-Cloning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfkTM9TjUCRx",
        "cellView": "form",
        "outputId": "b206ac74-bd66-4ccb-ccdd-9c74f1e9dc65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Setup CorentinJ/Real-Time-Voice-Cloning\n",
        "\n",
        "#@markdown * clone the project\n",
        "#@markdown * download pretrained models\n",
        "#@markdown * initialize the voice cloning models\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/CorentinJ/Real-Time-Voice-Cloning.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # clone and install\n",
        "  !git clone -q --recursive {git_repo_url}\n",
        "  # install dependencies\n",
        "  !cd {project_name} && pip install -q -r requirements.txt\n",
        "  !pip install -q gdown\n",
        "  !apt-get install -qq libportaudio2\n",
        "  !pip install -q https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip\n",
        "\n",
        "  # download pretrained model\n",
        "  !cd {project_name} && wget https://github.com/blue-fish/Real-Time-Voice-Cloning/releases/download/v1.0/pretrained.zip && unzip -o pretrained.zip\n",
        "\n",
        "import sys\n",
        "sys.path.append(project_name)\n",
        "\n",
        "from IPython.display import display, Audio, clear_output\n",
        "from IPython.utils import io\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from dl_colab_notebooks.audio import record_audio, upload_audio\n",
        "\n",
        "from synthesizer.inference import Synthesizer\n",
        "from encoder import inference as encoder\n",
        "from vocoder import inference as vocoder\n",
        "from pathlib import Path\n",
        "\n",
        "encoder.load_model(project_name / Path(\"encoder/saved_models/pretrained.pt\"))\n",
        "synthesizer = Synthesizer(project_name / Path(\"synthesizer/saved_models/pretrained/pretrained.pt\"))\n",
        "vocoder.load_model(project_name / Path(\"vocoder/saved_models/pretrained/pretrained.pt\"))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "\u001b[K     |████████████████████████████████| 80 kB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 676 kB 25.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.3 MB 29.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 74 kB/s \n",
            "\u001b[K     |████████████████████████████████| 241 kB 52.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 26.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 66 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 34.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59.9 MB 34 kB/s \n",
            "\u001b[K     |████████████████████████████████| 317 kB 44.8 MB/s \n",
            "\u001b[?25h  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 1.15.2 requires gast==0.2.2, but you have gast 0.4.0 which is incompatible.\n",
            "lucid 0.3.10 requires numpy<=1.19, but you have numpy 1.19.4 which is incompatible.\n",
            "kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 148489 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "\u001b[K     \\ 3.0 kB 3.0 MB/s\n",
            "\u001b[?25h  Building wheel for Deep-Learning-Colab-Notebook-Utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "--2021-08-28 12:54:31--  https://github.com/blue-fish/Real-Time-Voice-Cloning/releases/download/v1.0/pretrained.zip\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/274049886/9764da00-6919-11eb-8444-e8027183f04f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210828%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210828T125431Z&X-Amz-Expires=300&X-Amz-Signature=57507711cc9bc7867c4b79e78812b9baa302061b07645604f7c8393210677278&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=274049886&response-content-disposition=attachment%3B%20filename%3Dpretrained.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-08-28 12:54:31--  https://github-releases.githubusercontent.com/274049886/9764da00-6919-11eb-8444-e8027183f04f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210828%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210828T125431Z&X-Amz-Expires=300&X-Amz-Signature=57507711cc9bc7867c4b79e78812b9baa302061b07645604f7c8393210677278&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=274049886&response-content-disposition=attachment%3B%20filename%3Dpretrained.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.109.154, 185.199.111.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.109.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 397171814 (379M) [application/octet-stream]\n",
            "Saving to: ‘pretrained.zip’\n",
            "\n",
            "pretrained.zip      100%[===================>] 378.77M  25.7MB/s    in 15s     \n",
            "\n",
            "2021-08-28 12:54:47 (24.9 MB/s) - ‘pretrained.zip’ saved [397171814/397171814]\n",
            "\n",
            "Archive:  pretrained.zip\n",
            "   creating: encoder/saved_models/\n",
            "  inflating: encoder/saved_models/pretrained.pt  \n",
            "   creating: synthesizer/saved_models/\n",
            "   creating: synthesizer/saved_models/pretrained/\n",
            "  inflating: synthesizer/saved_models/pretrained/pretrained.pt  \n",
            "   creating: vocoder/saved_models/\n",
            "   creating: vocoder/saved_models/pretrained/\n",
            "  inflating: vocoder/saved_models/pretrained/pretrained.pt  \n",
            "Loaded encoder \"pretrained.pt\" trained to step 1564501\n",
            "Synthesizer using device: cuda\n",
            "Building Wave-RNN\n",
            "Trainable Parameters: 4.481M\n",
            "Loading model weights at Real-Time-Voice-Cloning/vocoder/saved_models/pretrained/pretrained.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBeMoBxLkDKN",
        "cellView": "form",
        "outputId": "51212066-76fd-4ed1-aafe-c7cce07ca3a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34,
          "referenced_widgets": [
            "801675df44c54402812089ec9d41fc98",
            "65bad0699f154671bf734f6f8234a085",
            "828540d503694590ac6bb5e24135afd1"
          ]
        }
      },
      "source": [
        "#@title Record or Upload\n",
        "#@markdown * Either record audio from microphone or upload audio from file (.mp3 or .wav) \n",
        "\n",
        "SAMPLE_RATE = 22050\n",
        "record_or_upload = \"Record\" #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n",
        "record_seconds =   10#@param {type:\"number\", min:1, max:10, step:1}\n",
        "\n",
        "embedding = None\n",
        "def _compute_embedding(audio):\n",
        "  display(Audio(audio, rate=SAMPLE_RATE, autoplay=True))\n",
        "  global embedding\n",
        "  embedding = None\n",
        "  embedding = encoder.embed_utterance(encoder.preprocess_wav(audio, SAMPLE_RATE))\n",
        "def _record_audio(b):\n",
        "  clear_output()\n",
        "  audio = record_audio(record_seconds, sample_rate=SAMPLE_RATE)\n",
        "  _compute_embedding(audio)\n",
        "def _upload_audio(b):\n",
        "  clear_output()\n",
        "  audio = upload_audio(sample_rate=SAMPLE_RATE)\n",
        "  _compute_embedding(audio)\n",
        "\n",
        "if record_or_upload == \"Record\":\n",
        "  button = widgets.Button(description=\"Record Your Voice\")\n",
        "  button.on_click(_record_audio)\n",
        "  display(button)\n",
        "else:\n",
        "  #button = widgets.Button(description=\"Upload Voice File\")\n",
        "  #button.on_click(_upload_audio)\n",
        "  _upload_audio(\"\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting recording for 10 seconds...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "      const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "      const b2text = blob => new Promise(resolve => {\n",
              "        const reader = new FileReader()\n",
              "        reader.onloadend = e => resolve(e.srcElement.result)\n",
              "        reader.readAsDataURL(blob)\n",
              "      })\n",
              "      var record = time => new Promise(async resolve => {\n",
              "        stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "        recorder = new MediaRecorder(stream)\n",
              "        chunks = []\n",
              "        recorder.ondataavailable = e => chunks.push(e.data)\n",
              "        recorder.start()\n",
              "        await sleep(time)\n",
              "        recorder.onstop = async ()=>{\n",
              "          blob = new Blob(chunks)\n",
              "          text = await b2text(blob)\n",
              "          resolve(text)\n",
              "        }\n",
              "        recorder.stop()\n",
              "      })\n",
              "      "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZjKkvGF1Y-i",
        "cellView": "form",
        "outputId": "cf339135-4e0d-4add-bd74-f36cc5f47e75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Synthesize a text { run: \"auto\" }\n",
        "text = \"One of the two people who tested positive for the novel coronavirus in the United Kingdom is a student at the University of York in northern England.\" #@param {type:\"string\"}\n",
        "  \n",
        "def synthesize(embed, text):\n",
        "  print(\"Synthesizing new audio...\")\n",
        "  #with io.capture_output() as captured:\n",
        "  specs = synthesizer.synthesize_spectrograms([text], [embed])\n",
        "  generated_wav = vocoder.infer_waveform(specs[0])\n",
        "  generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
        "  clear_output()\n",
        "  display(Audio(generated_wav, rate=synthesizer.sample_rate, autoplay=True))\n",
        "\n",
        "if embedding is None:\n",
        "  print(\"first record a voice or upload a voice file!\")\n",
        "else:\n",
        "  synthesize(embedding, text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first record a voice or upload a voice file!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}